{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac57a207",
   "metadata": {},
   "source": [
    "### Imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c5c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d57650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSE2019_PATH = os.path.join(os.curdir, 'datasets', 'VerSe2019')\n",
    "OUTPUT_PATH = os.path.join(os.curdir, 'output', 'VerSe2019.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6adf44",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_s = [] # np.array with sagittal MIPs\n",
    "imgs_f = [] # np.array with frontal MIPs\n",
    "v_levels = [] # np.array with labels in mm\n",
    "ids = [] # np.array with CTs identifiers\n",
    "thicks = [] # np.array with CTs slices' thicknesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9739ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_paths = glob.glob(os.path.join(VERSE2019_PATH, '*', 'rawdata', '*', '*.nii.gz'))\n",
    "json_paths = glob.glob(os.path.join(VERSE2019_PATH, '*', 'derivatives', '*', '*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ct_path in enumerate(ct_paths):\n",
    "    print(i)\n",
    "\n",
    "    # --- CT id naming convention ---\n",
    "    name = ct_path.split('/')[-1].split('.')[0][:-3]\n",
    "    dataset_type = ct_path.split('/')[3][15:] \n",
    "        \n",
    "    if dataset_type == 'training':\n",
    "        dataset_type = 'train'\n",
    "    elif dataset_type == 'validation':\n",
    "        dataset_type = 'val'\n",
    "    \n",
    "    ct_id = f'{name}_{dataset_type}'\n",
    "    \n",
    "    if ct_id in ids:\n",
    "        print(f'{ct_id} already processed...')\n",
    "        continue\n",
    "    \n",
    "    print(ct_id)\n",
    "    \n",
    "    # --- finding & loading corresponding .json ---\n",
    "    json_path = [path for path in json_paths if name in path][0]\n",
    "    # ctds_list = utils.load_centroids(json_path)\n",
    "    ctds = utils.load_centroids(json_path)\n",
    "    \n",
    "    # --- preprocessing CT ---\n",
    "    img = nib.load(ct_path)\n",
    "\n",
    "    img_unsampled = utils.reorient_to(img, axcodes_to=('I', 'P', 'L')) # for calculating spacings\n",
    "\n",
    "    # 1mm normalization + axes order normalization\n",
    "    img = utils.reorient_to(img, axcodes_to=('I', 'P', 'L')) # CT in height x depth x width order\n",
    "    ctds = utils.reorient_centroids_to(ctds, img)\n",
    "\n",
    "    img = utils.resample_nib(img, voxel_spacing=(1, 1, 1), order=3)\n",
    "    ctds = utils.rescale_centroids(ctds, img, (1, 1, 1))\n",
    "     \n",
    "    ctds_dict = {seq[0]: seq[1] for seq in ctds if seq[0] in (19, 22)}\n",
    "    if not ctds_dict:\n",
    "        print(f'No T12 & L3 for {name}...')\n",
    "        continue\n",
    "    \n",
    "    slice_thickness = img.shape[0] / img_unsampled.shape[0]\n",
    "    width_spacing = img.shape[2] / img_unsampled.shape[2]\n",
    "\n",
    "    # getting np.array & transposing axes to assumed convention (depth x width x height)\n",
    "    img = img.get_fdata()\n",
    "    img = np.transpose(img, axes=[1, 2, 0])\n",
    "\n",
    "    # converting to HU scale\n",
    "    img += 24 # to be consistent with -1000 for air (-1024 in VerSe)\n",
    "    \n",
    "    # mass center calculation & 0ing everything outside body\n",
    "    img, center_h, center_w = utils.get_mass_center(img)\n",
    "        \n",
    "    # frontal MIP\n",
    "    img_cropped = utils.crop_ct(img, center_h, center_w, for_frontal=True)\n",
    "    img_mip_f = np.amax(img_cropped, axis=0)\n",
    "    img_mip_f = np.swapaxes(img_mip_f, 0, 1)\n",
    "\n",
    "    # sagittal MIP\n",
    "    try:\n",
    "        img_cropped = utils.crop_ct(img, center_h, center_w, for_frontal=False, \n",
    "                                    sides_cut=40) # 40 instead of default 30\n",
    "        img_mip_s = np.amax(img_cropped, axis=1) \n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        print(f'Sagittal crop impossible for {ct_id} of shape {img.shape}...')\n",
    "        continue\n",
    "        \n",
    "    img_mip_s = np.swapaxes(img_mip_s, 0, 1)\n",
    "\n",
    "    # calculating labels in mm\n",
    "    t12_lvl = -1 if not 19 in ctds_dict else int(ctds_dict[19])\n",
    "    l3_lvl = -1 if not 22 in ctds_dict else int(ctds_dict[22])\n",
    "    \n",
    "    # saving\n",
    "    imgs_s.append(img_mip_s)\n",
    "    imgs_f.append(img_mip_f)\n",
    "    v_levels.append([t12_lvl, l3_lvl])\n",
    "    ids.append(ct_id)\n",
    "    thicks.append(slice_thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5de75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting to .npz\n",
    "imgs_s = np.asarray(imgs_s)\n",
    "imgs_f = np.asarray(imgs_f)\n",
    "v_levels = np.asarray(v_levels)\n",
    "ids = np.asarray(ids)\n",
    "thicks = np.asarray(thicks)\n",
    "n_mips = imgs_s.shape[0]\n",
    "\n",
    "np.savez_compressed(OUTPUT_PATH, imgs_s=imgs_s, imgs_f=imgs_f,\n",
    "                    v_levels=v_levels, ids=ids, thicks=thicks, n_mips=n_mips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
